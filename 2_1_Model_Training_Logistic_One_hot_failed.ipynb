{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T10:30:47.113017Z",
     "start_time": "2024-11-16T10:30:46.174156200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy scipy scikit-learn --user\n",
    "# !pip show numpy scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T10:33:34.785407100Z",
     "start_time": "2024-11-16T10:33:31.097665600Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/q91_28dx1cs9z4ty_4g_hrwc0000gn/T/ipykernel_13464/217804304.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('merged_df_abstract_preprocess_all.csv')\n"
     ]
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('merged_df_abstract_preprocess_all.csv')\n",
    "df = df.dropna(subset=['processed_abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T10:33:37.224246600Z",
     "start_time": "2024-11-16T10:33:37.218711Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311557, 20)\n",
      "Index(['Title', 'Abstract', 'Disciplines', 'Keywords', 'Source',\n",
      "       'Disciplines_split', 'Astronomy', 'Biology', 'Chemistry',\n",
      "       'Computer Science', 'Economics', 'Education & instruction',\n",
      "       'Electrical Engineering', 'European & international law', 'History',\n",
      "       'Mathematics', 'Physics', 'Social Sciences', 'Statistics',\n",
      "       'processed_abstract'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T11:49:24.932232900Z",
     "start_time": "2024-11-16T11:49:14.323376400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vectorize the Text Data using TF-IDF\n",
    "vectorizer_Logistic_one_hot = TfidfVectorizer()\n",
    "X = vectorizer_Logistic_one_hot.fit_transform(df['processed_abstract'])  # Text data turned into numerical format\n",
    "\n",
    "# Define the labels (One-hot encoded)\n",
    "labels = [\n",
    "    'Astronomy', 'Biology', 'Chemistry', 'Computer Science', 'Economics', 'Education & instruction',\n",
    "    'Electrical Engineering', 'European & international law', 'History', 'Mathematics', 'Physics',\n",
    "    'Social Sciences', 'Statistics'\n",
    "]\n",
    "\n",
    "y = df[labels]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T11:49:39.838881800Z",
     "start_time": "2024-11-16T11:49:39.425817900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save vectorizer\n",
    "import joblib\n",
    "joblib.dump(vectorizer_Logistic_one_hot, '1_vectorizer_Logistic_one_hot.joblib')\n",
    "vectorizer_Logistic_one_hot = joblib.load('1_vectorizer_Logistic_one_hot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T11:05:38.039971400Z",
     "start_time": "2024-11-16T11:04:14.524322Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                   Astronomy       0.98      0.92      0.95      4527\n",
      "                     Biology       0.93      0.41      0.57       292\n",
      "                   Chemistry       0.73      0.13      0.22       291\n",
      "            Computer Science       0.94      0.93      0.94     28514\n",
      "                   Economics       0.73      0.25      0.37       561\n",
      "     Education & instruction       0.79      0.41      0.54       182\n",
      "      Electrical Engineering       0.76      0.50      0.60      4363\n",
      "European & international law       0.93      0.26      0.40        97\n",
      "                     History       0.85      0.29      0.43       134\n",
      "                 Mathematics       0.92      0.88      0.90     12638\n",
      "                     Physics       0.94      0.92      0.93     17342\n",
      "             Social Sciences       0.92      0.30      0.45       216\n",
      "                  Statistics       0.84      0.53      0.65      1662\n",
      "\n",
      "                   micro avg       0.93      0.87      0.90     70819\n",
      "                   macro avg       0.87      0.52      0.61     70819\n",
      "                weighted avg       0.92      0.87      0.89     70819\n",
      "                 samples avg       0.90      0.89      0.89     70819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claraduchossois/Documents/MADS/MADS Sem 3/NLP/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1 Logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "Model_Logistic_Multi = MultiOutputClassifier(logreg)\n",
    "Model_Logistic_Multi.fit(X_train, y_train)\n",
    "\n",
    "y_pred = Model_Logistic_Multi.predict(X_test)\n",
    "\n",
    "report_Logistic_Multi = classification_report(y_test, y_pred, target_names=labels)\n",
    "print(report_Logistic_Multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T11:08:14.668070400Z",
     "start_time": "2024-11-16T11:08:14.646052900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/1_Model_Logistic_Multi.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel_Logistic_Multi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel/1_Model_Logistic_Multi.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m Model_Logistic_Multi \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/1_Model_Logistic_Multi.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MADS/MADS Sem 3/NLP/env/lib/python3.9/site-packages/joblib/numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/1_Model_Logistic_Multi.joblib'"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(Model_Logistic_Multi, 'model/1_Model_Logistic_Multi.joblib')\n",
    "Model_Logistic_Multi = joblib.load('model/1_Model_Logistic_Multi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T11:50:13.758741Z",
     "start_time": "2024-11-16T11:50:13.731296400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astronomy\n",
      "telescope: 10.61206887020964\n",
      "galaxy: 10.542583954989995\n",
      "star: 8.44685975945685\n",
      "planet: 8.22455796472463\n",
      "observation: 7.7490029506349485\n",
      "stellar: 7.163741995434713\n",
      "redshift: 7.097421063272092\n",
      "sky: 6.77311948449089\n",
      "solar: 6.339692439438203\n",
      "atmosphere: 6.337198250973576\n",
      "\n",
      "Biology\n",
      "protein: 6.65425505777634\n",
      "receptor: 5.814041213731296\n",
      "neuronal: 5.5583858255848275\n",
      "activity: 5.542227377288786\n",
      "neuron: 5.2599464392938975\n",
      "gene: 5.166189910678739\n",
      "cell: 4.959676495028663\n",
      "neural: 4.796108374311479\n",
      "stimulus: 4.602840148150857\n",
      "brain: 4.230271826926343\n",
      "\n",
      "Chemistry\n",
      "molecule: 7.21337000435448\n",
      "molecular: 6.398952650157769\n",
      "reaction: 5.645484579603119\n",
      "energy: 5.3645313617222214\n",
      "electron: 4.43659695261979\n",
      "electronic: 4.100129851294552\n",
      "chemical: 4.079821378273239\n",
      "calculation: 3.7382054447463706\n",
      "excited: 3.404122406470716\n",
      "dynamic: 3.289124323409524\n",
      "\n",
      "Computer Science\n",
      "robot: 11.032094955786354\n",
      "language: 10.318395216834526\n",
      "dataset: 9.44480251837512\n",
      "task: 7.753036299389881\n",
      "art: 7.089228669658545\n",
      "code: 6.734199365794499\n",
      "query: 6.361525609755421\n",
      "reasoning: 6.039563212616129\n",
      "input: 5.835061840019748\n",
      "human: 5.646366329407201\n",
      "\n",
      "Economics\n",
      "economic: 7.879756537970113\n",
      "choice: 5.99380202474537\n",
      "preference: 5.588728600399244\n",
      "market: 5.2795271419192895\n",
      "firm: 5.0779790852161435\n",
      "price: 4.949926482954653\n",
      "equilibrium: 4.5934959829717785\n",
      "income: 4.3195904665783695\n",
      "country: 4.234634801970903\n",
      "policy: 4.166411174266222\n",
      "\n",
      "Education & instruction\n",
      "education: 7.640393191417859\n",
      "child: 7.2791715777311845\n",
      "school: 7.13849993466603\n",
      "student: 6.786694667354023\n",
      "teacher: 5.486493137765699\n",
      "teaching: 3.9965335275939324\n",
      "educational: 3.8181709564474415\n",
      "science: 3.243964445064124\n",
      "practice: 2.848213596654328\n",
      "activity: 2.8286180527687734\n",
      "\n",
      "Electrical Engineering\n",
      "speech: 9.276699198003422\n",
      "audio: 7.194763912817136\n",
      "codec: 6.766832996055814\n",
      "speaker: 6.714890120303821\n",
      "sound: 6.084888486421694\n",
      "propose: 5.0405952137493575\n",
      "music: 4.929971603678774\n",
      "bitrate: 4.875941418303277\n",
      "system: 4.6205312439690465\n",
      "paper: 4.611492734794793\n",
      "\n",
      "European & international law\n",
      "law: 8.439350008717552\n",
      "international: 6.158915570442895\n",
      "legal: 6.155408048539412\n",
      "right: 5.419927844494542\n",
      "national: 5.163153501695681\n",
      "article: 4.019094958647599\n",
      "protection: 3.943222191587718\n",
      "court: 3.4942915912903385\n",
      "administrative: 3.0643465868440773\n",
      "constitutional: 3.0121128698439446\n",
      "\n",
      "History\n",
      "history: 11.34574293190309\n",
      "digital: 7.448713264760139\n",
      "war: 6.584252831386512\n",
      "historical: 6.567597597131421\n",
      "medium: 4.245511474180526\n",
      "archive: 4.193224729148593\n",
      "historian: 4.059572787232542\n",
      "cultural: 3.1954843415606895\n",
      "project: 3.073828127348398\n",
      "research: 2.99997948318741\n",
      "\n",
      "Mathematics\n",
      "prove: 9.21342086278701\n",
      "numerical: 6.88136693136312\n",
      "paper: 6.6122336894814415\n",
      "establish: 5.339646888014966\n",
      "article: 5.093733720267657\n",
      "asymptotic: 4.960715186077552\n",
      "regularity: 4.947388902291033\n",
      "existence: 4.937647850632202\n",
      "integer: 4.836550847905695\n",
      "in: 4.787633731669849\n",
      "\n",
      "Physics\n",
      "quantum: 16.179983459838724\n",
      "qubit: 9.295706715791047\n",
      "spacetime: 7.428155200919985\n",
      "experimental: 6.969134988633215\n",
      "gauge: 6.350442491744331\n",
      "entanglement: 6.155892526312223\n",
      "seismic: 6.046635525639837\n",
      "state: 5.9511928840763195\n",
      "quark: 5.8057669796568225\n",
      "calculation: 5.736071032581345\n",
      "\n",
      "Social Sciences\n",
      "country: 4.542433268538569\n",
      "social: 4.45069079340108\n",
      "age: 4.32533281749569\n",
      "life: 4.1671786049920465\n",
      "people: 3.582045148220157\n",
      "person: 3.442049946432887\n",
      "university: 3.361596619997069\n",
      "youth: 3.334956428949769\n",
      "subjective: 3.1959911117554842\n",
      "research: 3.1915389014794924\n",
      "\n",
      "Statistics\n",
      "statistical: 7.785998137562659\n",
      "trial: 6.222457923200354\n",
      "illustrate: 5.60067957634258\n",
      "copula: 5.066039707703997\n",
      "simulation: 5.037390102228511\n",
      "datum: 4.9914988733225085\n",
      "covariate: 4.692885553103975\n",
      "study: 4.579344298838979\n",
      "multivariate: 4.270792491165505\n",
      "dependence: 4.195736620425528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_names = np.array(vectorizer_Logistic_one_hot.get_feature_names_out())\n",
    "coefficients = Model_Logistic_Multi.estimators_\n",
    "\n",
    "top_n = 10\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    coef = coefficients[i].coef_[0]\n",
    "    top_keywords_idx = np.argsort(coef)[-top_n:][::-1]\n",
    "    print(label)\n",
    "\n",
    "    for idx in top_keywords_idx:\n",
    "        print(f\"{feature_names[idx]}: {coef[idx]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T11:40:09.550852500Z",
     "start_time": "2024-11-16T11:40:06.297397500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n",
      "    app.start()\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"D:\\软件\\Python\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"D:\\软件\\Python\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"D:\\软件\\Python\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 529, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 518, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 424, in dispatch_shell\n",
      "    await result\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 766, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\cshch\\AppData\\Local\\Temp\\ipykernel_13820\\982599698.py\", line 2, in <module>\n",
      "    import spacy\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\thinc\\types.py\", line 25, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"D:\\软件\\Python\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "D:\\软件\\Python\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# Creating the 'preprocess' function\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess(text):\n",
    "    text_sub = re.sub(r\"^\\[en\\]\\s*\", \"\", text) # delete the [en] in the beginning\n",
    "    # text_rm_punc = text_sub.translate(str.maketrans(\"\", \"\", string.punctuation)) # Remove punctuation in the following\n",
    "    doc = nlp(str(text_sub))\n",
    "\n",
    "    # Tokenization and Remove unwanted characters\n",
    "    tokens = [token.text for token in doc if not token.is_punct]  # Removing punctuation and get tokens\n",
    "    # print(\"Cleaned Tokens:\", tokens)\n",
    "\n",
    "    # Stop Word Removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words and token.strip()]\n",
    "    # print(\"Filtered Tokens:\", filtered_tokens)\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if token.text.lower() in filtered_tokens]\n",
    "    # print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
    "\n",
    "    # Stemming\n",
    "    # stemmer = PorterStemmer()\n",
    "    # stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens] # Didn't do this step to remain the meaning of the words\n",
    "    # print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "\n",
    "    # Correct spelling using TextBlob\n",
    "    # corrected_text = ' '.join(stemmed_tokens)  # Join tokens into a string\n",
    "    # blob = TextBlob(corrected_text)\n",
    "    # corrected_review = blob.correct()\n",
    "    # print(\"Corrected Review:\", corrected_review)\n",
    "\n",
    "    return ' '.join(lemmatized_tokens) # Return lemmatized tokens as a space-separated string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T11:51:08.738923300Z",
     "start_time": "2024-11-16T11:51:08.725398400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new text: This is a new scientific paper on artificial intelligence in physics and astronomy.\n",
      "new text processed: new scientific paper artificial intelligence physics astronomy\n",
      "vectorizer: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Predicted probabilities structure: [array([[0.6979679, 0.3020321]]), array([[0.995078, 0.004922]]), array([[0.99881607, 0.00118393]]), array([[0.91967136, 0.08032864]]), array([[0.98833598, 0.01166402]]), array([[0.99792144, 0.00207856]]), array([[0.98454621, 0.01545379]]), array([[0.99734856, 0.00265144]]), array([[0.9955249, 0.0044751]]), array([[0.63706154, 0.36293846]]), array([[0.90728666, 0.09271334]]), array([[0.99646474, 0.00353526]]), array([[0.99519003, 0.00480997]])]\n",
      "Predicted labels: []\n"
     ]
    }
   ],
   "source": [
    "new_text = \"This is a new scientific paper on artificial intelligence in physics and astronomy.\"\n",
    "new_text_processed = preprocess(new_text)\n",
    "new_text_processed_vectorizer = vectorizer_Logistic_one_hot.transform([new_text_processed])  # vectorizer in training\n",
    "\n",
    "\n",
    "predicted_probabilities = Model_Logistic_Multi.predict_proba(new_text_processed_vectorizer)\n",
    "\n",
    "print(f\"new text: {new_text}\")\n",
    "print(f\"new text processed: {new_text_processed}\")\n",
    "\n",
    "\n",
    "print(\"Predicted probabilities structure:\", predicted_probabilities)\n",
    "\n",
    "\n",
    "predicted_labels = []\n",
    "\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    prob = predicted_probabilities[i][0][1]\n",
    "\n",
    "    if prob > 0.5:\n",
    "        predicted_labels.append(label)\n",
    "print(f\"Predicted labels: {predicted_labels}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
